{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy as sp\n",
    "import pandas as pd\n",
    "# from scipy.stats import f, f_oneway\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_table(\"estimators.csv\", decimal=\".\", quoting=2, sep=\",\", names = [\"steps\", \"upper\", \"lower\"])\n",
    "data_finite = pd.read_table(\"estimators_finite.csv\", decimal=\".\", quoting=2, sep=\",\", names = [\"steps\", \"upper\", \"lower\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read general delimited file into DataFrame\n",
      "\n",
      "Also supports optionally iterating or breaking of the file\n",
      "into chunks.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "filepath_or_buffer : string or file handle / StringIO\n",
      "    The string could be a URL. Valid URL schemes include\n",
      "    http, ftp, s3, and file. For file URLs, a\n",
      "    host is expected. For instance, a local file could be\n",
      "    file ://localhost/path/to/table.csv\n",
      "sep : string, default \\t (tab-stop)\n",
      "    Delimiter to use. Regular expressions are accepted.\n",
      "engine : {'c', 'python'}\n",
      "    Parser engine to use. The C engine is faster while the python engine is\n",
      "    currently more feature-complete.\n",
      "lineterminator : string (length 1), default None\n",
      "    Character to break file into lines. Only valid with C parser\n",
      "quotechar : string (length 1)\n",
      "    The character used to denote the start and end of a quoted item. Quoted\n",
      "    items can include the delimiter and it will be ignored.\n",
      "quoting : int or csv.QUOTE_* instance, default None\n",
      "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    Default (None) results in QUOTE_MINIMAL behavior.\n",
      "skipinitialspace : boolean, default False\n",
      "    Skip spaces after delimiter\n",
      "escapechar : string (length 1), default None\n",
      "    One-character string used to escape delimiter when quoting is QUOTE_NONE.\n",
      "dtype : Type name or dict of column -> type\n",
      "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "    (Unsupported with engine='python')\n",
      "compression : {'gzip', 'bz2', None}, default None\n",
      "    For on-the-fly decompression of on-disk data\n",
      "dialect : string or csv.Dialect instance, default None\n",
      "    If None defaults to Excel dialect. Ignored if sep longer than 1 char\n",
      "    See csv.Dialect documentation for more details\n",
      "header : int, list of ints\n",
      "    Row number(s) to use as the column names, and the start of the\n",
      "    data.  Defaults to 0 if no ``names`` passed, otherwise ``None``. Explicitly\n",
      "    pass ``header=0`` to be able to replace existing names. The header can be\n",
      "    a list of integers that specify row locations for a multi-index on the\n",
      "    columns E.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "    skipped (e.g. 2 in this example are skipped). Note that this parameter\n",
      "    ignores commented lines and empty lines if ``skip_blank_lines=True``, so header=0\n",
      "    denotes the first line of data rather than the first line of the file.\n",
      "skiprows : list-like or integer\n",
      "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "    at the start of the file\n",
      "index_col : int or sequence or False, default None\n",
      "    Column to use as the row labels of the DataFrame. If a sequence is given, a\n",
      "    MultiIndex is used. If you have a malformed file with delimiters at the end\n",
      "    of each line, you might consider index_col=False to force pandas to _not_\n",
      "    use the first column as the index (row names)\n",
      "names : array-like\n",
      "    List of column names to use. If file contains no header row, then you\n",
      "    should explicitly pass header=None\n",
      "prefix : string, default None\n",
      "    Prefix to add to column numbers when no header, e.g 'X' for X0, X1, ...\n",
      "na_values : list-like or dict, default None\n",
      "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "    per-column NA values\n",
      "true_values : list\n",
      "    Values to consider as True\n",
      "false_values : list\n",
      "    Values to consider as False\n",
      "keep_default_na : bool, default True\n",
      "    If na_values are specified and keep_default_na is False the default NaN\n",
      "    values are overridden, otherwise they're appended to\n",
      "parse_dates : boolean, list of ints or names, list of lists, or dict\n",
      "    If True -> try parsing the index.\n",
      "    If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column.\n",
      "    If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column.\n",
      "    {'foo' : [1, 3]} -> parse columns 1, 3 as date and call result 'foo'\n",
      "    A fast-path exists for iso8601-formatted dates.\n",
      "keep_date_col : boolean, default False\n",
      "    If True and parse_dates specifies combining multiple columns then\n",
      "    keep the original columns.\n",
      "date_parser : function\n",
      "    Function to use for converting a sequence of string columns to an\n",
      "    array of datetime instances. The default uses dateutil.parser.parser\n",
      "    to do the conversion. Pandas will try to call date_parser in three different\n",
      "    ways, advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "    (as defined by parse_dates) as arguments; 2) concatenate (row-wise) the string\n",
      "    values from the columns defined by parse_dates into a single array and pass\n",
      "    that; and 3) call date_parser once for each row using one or more strings\n",
      "    (corresponding to the columns defined by parse_dates) as arguments.\n",
      "dayfirst : boolean, default False\n",
      "    DD/MM format dates, international and European format\n",
      "thousands : str, default None\n",
      "    Thousands separator\n",
      "comment : str, default None\n",
      "    Indicates remainder of line should not be parsed. If found at the\n",
      "    beginning of a line, the line will be ignored altogether. This parameter\n",
      "    must be a single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "    fully commented lines are ignored by the parameter `header`\n",
      "    but not by `skiprows`. For example, if comment='#', parsing\n",
      "    '#empty\\na,b,c\\n1,2,3' with `header=0` will result in 'a,b,c' being\n",
      "    treated as the header.\n",
      "decimal : str, default '.'\n",
      "    Character to recognize as decimal point. E.g. use ',' for European data\n",
      "nrows : int, default None\n",
      "    Number of rows of file to read. Useful for reading pieces of large files\n",
      "iterator : boolean, default False\n",
      "    Return TextFileReader object\n",
      "chunksize : int, default None\n",
      "    Return TextFileReader object for iteration\n",
      "skipfooter : int, default 0\n",
      "    Number of lines at bottom of file to skip (Unsupported with engine='c')\n",
      "converters : dict, default None\n",
      "    Dict of functions for converting values in certain columns. Keys can either\n",
      "    be integers or column labels\n",
      "verbose : boolean, default False\n",
      "    Indicate number of NA values placed in non-numeric columns\n",
      "delimiter : string, default None\n",
      "    Alternative argument name for sep. Regular expressions are accepted.\n",
      "encoding : string, default None\n",
      "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "    standard encodings\n",
      "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_\n",
      "squeeze : boolean, default False\n",
      "    If the parsed data only contains one column then return a Series\n",
      "na_filter : boolean, default True\n",
      "    Detect missing value markers (empty strings and the value of na_values). In\n",
      "    data without any NAs, passing na_filter=False can improve the performance\n",
      "    of reading a large file\n",
      "usecols : array-like\n",
      "    Return a subset of the columns.\n",
      "    Results in much faster parsing time and lower memory usage.\n",
      "mangle_dupe_cols : boolean, default True\n",
      "    Duplicate columns will be specified as 'X.0'...'X.N', rather than 'X'...'X'\n",
      "tupleize_cols : boolean, default False\n",
      "    Leave a list of tuples on columns as is (default is to convert to\n",
      "    a Multi Index on the columns)\n",
      "error_bad_lines : boolean, default True\n",
      "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "    default cause an exception to be raised, and no DataFrame will be returned.\n",
      "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
      "    returned. (Only valid with C parser)\n",
      "warn_bad_lines : boolean, default True\n",
      "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "    \"bad line\" will be output. (Only valid with C parser).\n",
      "infer_datetime_format : boolean, default False\n",
      "    If True and parse_dates is enabled for a column, attempt to infer\n",
      "    the datetime format to speed up the processing\n",
      "skip_blank_lines : boolean, default True\n",
      "    If True, skip over blank lines rather than interpreting as NaN values\n",
      "\n",
      "Returns\n",
      "-------\n",
      "result : DataFrame or TextParser\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print pd.read_table.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.52578966\n",
      "3.85906011\n",
      "5.17038788\n",
      "7.16005886\n",
      "7.6815601\n",
      "9.66501471\n",
      "11.44538899\n",
      "13.49454087\n",
      "14.51501287\n"
     ]
    }
   ],
   "source": [
    "grouped = data.groupby(\"steps\")\n",
    "for (step, group) in grouped:\n",
    "    print (group[\"upper\"] - group[\"lower\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.83725615\n",
      "3.7328035\n",
      "5.27181947\n",
      "6.39057471\n",
      "8.32008171\n",
      "9.88505621\n",
      "11.1643417\n",
      "13.11625201\n",
      "15.06355685\n"
     ]
    }
   ],
   "source": [
    "grouped = data_finite.groupby(\"steps\")\n",
    "for (step, group) in grouped:\n",
    "    print (group[\"upper\"] - group[\"lower\"]).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
