%!TEX root = thesis.tex
\chapter{Применение Квази Монте-Карло для повышения точности оценок} % (fold)
\label{cha:QMC_for_variance_reduction}

Все методы, изложенные в главе \ref{cha:classic_approaches_to_option_pricing}, разработаны для того, чтобы за как можно меньшее время работы получить как можно более точную оценку для $V_0$. Получить меньшую дисперсию оценки (а, значит, более точную оценку) можно не только использованием более эффективного алгоритма, но и с помощью техник снижения дисперсии. 

Стандартные подходы к снижению дисперсии оценки по методу Монте-Карло используют случайную природу метода. Так, метод \emph{противоположных переменных} использует тот факт, что дисперсия суммы двух одинаково распределённых зависимых случайных величин $\xi$ и $\eta$ с отрицательной ковариацией $\mathrm{cov}\left(\xi, \eta\right) < 0$ равна 
$$\mathrm D\left(\xi + \eta\right) = \mathrm D \xi + 2 \mathrm{cov}\left(\xi, \eta\right) + \mathrm D\eta < 2 \mathrm D\eta.$$
Таким образом, использование в методе Монте-Карло вместо независимых одинаково распределённых случайных величин зависимых с отрицательной корреляцией позволяет снизить дисперсию оценки. Подробнее см.~\cite[раздел~4.2, стр.~205]{Glasserman2004}.

Метод \emph{контрольных переменных} также использует разложение дисперсии суммы двух случайных величин. Идея здесь состоит в том, что если взять две скоррелированных случайных величины $\xi$ и $\eta$, для одной из которых известно математическое ожидание (например, $\E\eta$), то на каждой реализации пары можно осуществлять коррекцию. Отклонение величины $\xi$ от $\E\xi$ похоже на отклонение $\eta$ от $\E\eta$; отсюда можно сконструировать скорректированную оценку $\bar\xi = \xi - b\left(\eta - \E\eta\right)$ и доказать, что при оптимальном $b$ $\mathrm D \bar\xi / \mathrm D\xi = 1 - \corr{\xi}{\eta}$. Подробнее см.~\cite[раздел~4.1, стр.~185]{Glasserman2004}.

Принципиально иной подход к снижению дисперсии появляется из области численного интегрирования. Математическое ожидание случайной величины, к которому стремится среднее множества её реализаций, является интегралом по носителю этой случайной величины (по определению математического ожидания). Поэтому метод Монте-Карло можно использовать для вычисления значения интегралов, и по той же причине его можно сравнивать с методами вычисления интеграла по регулярной сетке.

Метод квази Монте-Карло \cite{Chi2004} использует вместо последовательностей случайных точек детерминированные последовательности, обладающие свойством равномерно покрывать заданное пространство. Равномерность получаемой сетки и приводит к оценкам более точным, чем при использовании случайной сетки.

В этой главе изучаются особенности применения метода квази Монте-Карло для снижения дисперсии оценок в финансовых задачах (в частности, задаче оценки Американского опциона). В разделе~\ref{sec:qmc:qmc_definition} изложены основные сведения о квазислучайном методе: определение дискрепанса, неравенство Коксмы-Хлавки. В разделе~\ref{sec:qmc:randomization} описан метод рандомизации сдвигом, использующийся для получения более простых оценок погрешности квазислучайного метода, нежели неравенство Коксмы-Хлавки. Раздел~\ref{sec:qmc:monte_carlo_in_option_pricing} освещает основные вопросы, связанные с применением квази Монте-Карло к финансовым задачам. Для одного из этих вопросов решение известно, для второго в этом разделе предложено два варианта решения, которые сравниваются на численных экспериментах в разделе~\ref{sec:results:qmc_to_classical_methods}. %Также упомянуты более стандартные техники (метод противоположных переменных, метод контрольных переменных).

\section{Основные понятия} % (fold)
\label{sec:qmc:qmc_definition}

Отклонением (star discrepancy, $D^*$) последовательности из $N$ $d$-мерных случайных векторов в гиперкубе $\left[0;1\right]^d$ называют величину
$$D_N^* = D_N^*\left(X_1, \dots, X_N\right) = \sup_{v = (v_1, \dots, v_d) \in \left[0;1\right]^d} N \abs{\frac{\#\left\{ X_i \in J(v) \right\}}{N} - \prod_{j = 1}^d v_j},$$
где $J(v) = \left[0; v_1\right) \times \dots \times \left[0; v_d\right)$.

В случае, когда последовательность $\left\{ X_i\right\}_{i=1}^\infty$ такова, что $\forall N \: D_N^* \leq C_s \frac{(\ln N)^s}{N}$, последовательность называется последовательностью с низким отклонением (или с низким дискрепансом). С вычислительной точки зрения она представляет интерес из-за неравенства Коксмы-Хлавки: для интеграла, оцененного по этой последовательности, верно утверждение

\begin{equation}\label{eq:koksma-hlawka}
\abs{\int_{\left[0;1\right]^d} f(X) \dd X - \frac{1}{N}\sum_{i=1}^N f(X_i)} \leq \mathrm{Var}f\cdot \frac{D_N^*\left(X_1, \dots, X_N\right)}{N},
\end{equation}
где $\mathrm{Var}f$ -- вариация функции в смысле Харди-Краузе. Тогда при использовании последовательности с низким дискрепансом ошибка оценки интеграла имеет порядок $O\left(D_N^*\left(X_1, \dots, X_N\right)/N\right) = O\left((\ln N)^s / N^2\right)$. В случае обычного Монте-Карло размер отклонения оценки от математического ожидания имеет порядок $O(1 / \sqrt{N})$. Нетрудно заметить, что ошибка для квази Монте-Карло убывает быстрее.
% section quasi_mc_definition (end)

\section{Рандомизация} % (fold)
\label{sec:qmc:randomization}

Неравенство Коксмы-Хлавки \eqref{eq:koksma-hlawka} с точки зрения оценивания погрешности вычислений обладает двумя существенными недостатками: $\mathrm{Var}f$ сложно вычислить (особенно в тех случаях, когда функция вообще плохо описывается в явном виде, как в задаче оценки опциона) и оно даёт очень консервативную оценку (настоящая погрешность обычно существенно меньше, чем эта верхняя граница, см.~\cite[стр.\,22]{Maize1994}). Тогда как для большинства приложений необходим инструмент, позволяющий хорошо и быстро оценивать, насколько сильно ошибается оценка --- такой, как доверительные интервалы в методе Монте-Карло.

Одно из решений этой задачи --- рандомизация квазислучайных последовательностей. К последовательности применяется некоторое случайное преобразование, которое детерминированной последовательности сопоставляет реализации некоторой случайной величины.

Основные типы преобразований --- это случайный сдвиг (см.~\cite{Tuffin2004}) и случайные перестановки (см.~\cite{Owen1995}). В этой работе рассматривается случайный сдвиг как более удобный с точки зрения анализа дисперсии вариант.

Квази Монте-Карло последовательность $\left\{ X_i\right\}_{i \in \mathbb N} \subset \left[0;1\right]^d$, рандомизированная с помощью случайного сдвига --- это последовательность $\left\{ \hat X_i = X_i + \Xi_i \mod 1\right\}_{i \in \mathbb N} \subset \left[0;1\right]^d$, где $\Xi_i \sim \mathrm U\left[0;1\right]^d$. В случае, когда каждое $\hat X_i$ получено с помощью своей собственной реализации $\Xi_i$, результат ничем не отличается от стандартного Монте-Карло. В случае, когда последовательность длины $N$ делится на $g$ групп одинаковой длины $G = N / g$ и $\hat X_{\left(k - 1\right)G + l} = X_{\left(k - 1\right)G + l} + \Xi_k, \;k \in 1\mathbin{:}g,\,l \in 1\mathbin{:}G$ (то есть все элементы одной группы смещаются одинаково), полученная последовательность состоит из независимых между собой групп, которые зависимы внутри себя. При этом внутри каждой из таких групп взаимное расположение точек меняется мало (меняются только расстояния между теми точками, у которых значение какой-либо из координат превысило единицу после прибавления случайного вектора, и теми, у которых координаты <<не попали>> под оператор $\bmod$), что позволяет надеяться на сохранение преимуществ регулярной сетки. Наличие выигрыша в дисперсии при использовании такой рандомизации для задач численного интегрирования демонстрируют численные эксперименты в \cite{Tuffin2004}.

\subsection{Оценка дисперсии рандомизированного квази Монте-Карло} % (fold)
\label{ssub:qmc:randomization:variance_estimation}

В случае рандомизированного с помощью случайного сдвига квази Монте-Карло получаемые оценки $\Vhat$ являются одинаково распределёнными, но не независимыми. С использованием обозначений, аналогичных введённым в предыдущем абзаце, имеем $N$ оценок, каждая из которых принадлежит одной из $g$ групп. Пусть тогда $j$-ю оценку в $i$-й группе обозначает $\Vhat_{ij},\;\;i\in{1\mathbin{:}g},\;j \in{1\mathbin{:}G}$. По построению оценки из разных групп независимы, но оценки внутри одной группы имеют ненулевую корреляцию. 

Положим теперь 
$$\Vhat_{i\cdot} = \frac{1}{G}\sum_{j=1}^G \Vhat_{ij}.$$
Оценки $\Vhat_{i\cdot},\:i\in{1\mathbin{:}g}$ всё так же являются оценками $V$, но уже независимыми друг от друга. В таблицах в главе \ref{cha:numerical_results} для результатов квази Монте-Карло будем использовать следующие обозначения:
\begin{equation}\label{eq:rqmc_variance_estimation}
\begin{aligned}
    \Vhat &= \frac{1}{N}\sum_{i=1}^N \Vhat_{i\cdot} \\
    \mathrm{sd}\Vhat &= \sqrt{\frac{1}{g}\sum_{i=1}^g \left(\Vhat_{i\cdot} - \Vhat\right)^2} \\
    \mathrm{se}\Vhat &= \sqrt{\frac{1}{g}\sum_{i=1}^g \left(\Vhat_{i\cdot} - V\right)^2} \\
    \mathrm{bias}\Vhat &= \Vhat - V
\end{aligned}
\end{equation}

% section randomization (end)

\section{Приложение к задаче оценки стоимости Американского опциона} % (fold)
\label{sec:qmc:monte_carlo_in_option_pricing}

Несмотря на то, что сама возможность использования квази Монте-Карло в финансовых задачах в целом в литературе упоминается (\cite[глава~5]{Glasserman2004} и ссылки оттуда), подробного разбора метода в приложении к задаче оценки Американского опциона ещё не публиковалось.

В этом разделе освещены некоторые технические аспекты изпользования рандомизированного квази Монте-Карло и анализа его результатов для финансовых задач. %Также приведены численные результаты, согласно которым оценки, полученные с помощью рандомизированного квази Монте-Карло, действительно имеют меньшую дисперсию, чем оценки, полученные с помощью обычного Монте-Карло.

\subsection{Преобразование в нормальное распределение} % (fold)
\label{sub:qmc:option_pricing:uniform_normal_transform}

Квази Монте-Карло обычно рассматривается в контексте задачи интегрирования функции на $\left[0;1\right]^d$, а параллели проводятся с классическим Монте-Карло с использованием распределения $\mathrm U\left[0;1\right]^d$. В финансовых задачах же обычно используются нормальное и логнормальное распределения, но не равномерное. Поэтому первый вопрос, которому стоит уделить внимание --- это вопрос о корректном преобразовании, которое переводило бы последовательность с низким дискрепансом на $\left[0;1\right]^d$ в последовательность, обладающую теми же свойствами для нормального распределения. То есть, если определить дискрепанс по мере нормального распределения как 
$$\prescript{\mu}{}D_N^* = \prescript{\mu}{}D_N^*\left(X_1, \dots, X_N\right) = \sup_{v = (v_1, \dots, v_d) \in {\mathbb R^d}} N \abs{\frac{\#\left\{ X_i \in J(v) \right\}}{N} - \mu\left(J(v)\right)},$$
где $J(v) = \left[-\infty; v_1\right) \times \dots \times \left[-\infty; v_d\right)$, $\mu$ -- плотность $d$-мерного стандартного нормального распределения, то необходимо получить последовательность с наименьшим возможным $\prescript{\mu}{}D_N^*$ (формулировка близка к используемой в \cite{Oekten2011}). Согласно \cite{Oekten2011}, преобразование Бокса-Мюллера, применённое к <<распрямлённой>> квазислучайной последовательности, применимо в этом случае.

% subsection uniform_normal_transform (end)

\subsection{Выбор размерности} % (fold)
\label{sub:qmc:option_pricing:choice_of_dimension}

В контексте задачи многомерного интегрирования, в которой обычно говорится о квази Монте-Карло, размерность пространства, по которому происходит интегрирование, является условием задачи. В случае задачи оценивания опционов ответ на вопрос о том, какой же должна быть размерность квазислучайной последовательности, не столь очевиден.

Во-первых, все итоговые оценки по методу Монте-Карло имеют вид $\frac{1}{N}\sum_{i=1}^N \Vhat_i$, где $\Vhat_i$ -- это $i$-я реализация метода ($i$-е дерево, сетка и т.п.), то есть оценивается математическое ожидание случайной величины $\Vhat$. Тогда размерность интегрируемого пространства --- это конструктивная размерность алгоритма (КРА), суммарное число псевдо- или квазислучайных чисел, требуемых для получения одной оценки. Для оценки по случайным деревьям КРА равна $\mathrm{dim} X_t \cdot \sum_{i=1}^m b^i$, где $\mathrm{dim} X_t$ -- размерность базового актива, для метода сетки или наименьших квадратов -- $\mathrm{dim} X_t \cdot mb$.

Для значений параметров $m$ и $b$, дающих достаточно малую дисперсию при использовании обычного метода Монте-Карло (например, $m = 3$ и $b = 50$) конструктивная размерность линейных методов уже достаточно высока для квазислучайных последовательностей, а для метода случайных деревьев гораздо выше допустимых пределов. Так, для построения последовательности Холтона размерности 150 нужно получить 150 взаимно простых чисел. В случае, когда мы берём последовательность простых чисел, сто пятидесятое из них равно 853. Это означает, что по построению последовательности последняя координата первых её 852 точек будет идти равноотстоящими шагами от 0 до 1, что уже не очень похоже на случайные равномерно распределённые на $\left[0; 1\right]$ числа, и рандомизация сдвигом не исправит ситуацию.

Другой вариант --- это использование размерности, равной размерности базового актива. Мотивацией здесь может послужить то соображение, что оцениваемая величина --- это $V_0\left(x\right) = \maxset{h_0\left(x\right),\E\left[V_1\left(X_1\right)|X_0=x\right]}$ (см.~\eqref{eq:option-recursive}), которая в модели Блэка-Шоулса (в рамках которой проводились численные эксперименты) на самом деле является $m$-мерным интегралом по носителю $X_t$.

В главе~\ref{cha:numerical_results} приведены результаты экспериментов для обоих вариантов. Согласно этим результатам, вариант КРА работает лучше. Также в его пользу говорит то, что использование КРА не противоречит восприятию метода квази Монте-Карло как квадратурной формулы с одним свободным узлом (подробнее об этом подходе можно узнать в \cite{montekarlo1975}).

% subsection choice_of_dimension (end)

% chapter QMC_for_variance_reduction (end)